# --- Application Configuration ---

input.dir = input
output.dir = output
ollama.model = llama3

# --- Ollama Client Configuration ---
ollama.api.url = http://localhost:11434/api/chat
ollama.client.maxRetries = 3
ollama.client.retryDelayMs = 2000
ollama.client.requestTimeoutMinutes = 5

# --- Performance Tuning ---
processing.numThreads = 10